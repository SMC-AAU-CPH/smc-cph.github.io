---
layout: post
title: "First Weeks Of Portaling With Team B"
date: 2021-03-03 09:30:00 +0200
categories: networked-music
author: Henrik Sveen, Anders Lidal, Pedro Lucas, Willie Mandeville
image: /assets/image/2021_03_03_henrikhs_teamb_portal_first.jpg
keywords: portal, telematic-music, feedback, LoLa, latency
excerpt: "Starting to figure out the Portal and what we did/found out in the first weeks using it. How to play and some feedback fixing."
---

<figure style="float: auto">
   <img src="/assets/image/2021_03_03_henrikhs_teamb_portal_first.jpg" alt="" title="" width="auto"/> <figcaption>EQ-ing the master bus</figcaption>
</figure>

              The following section
                        presents Henrik's reflection
                                      on Team B's direction
                                                    in Portal connection

#### Playing together
My experience with telematic music performance has been close to nonexistent prior to joining the SMC master’s program. Not that doing music online is something I find totally uninteresting, but I think it has to do with my line of work and the relevance of doing music online instead of in the same physical space. So the experience has been quite new to me. Last fall we jumped into playing online together from our homes using JamKazam and such, which was a bumpy ride for many of us. Much because of struggles getting servers up and running, but also then having everything connected and figuring out how to navigate musically without seeing each other properly. It quickly became messy.

So with this experience in our telematic backpacks, playing together in the Portal seemed promising as the room is set up to be more audiovisual than explicitly audial. With everything running, which took some time, the first obstacle was getting the sound right. Sending many people’s instruments on a stereo connection, without a proper soundcheck, is a pretentious project for new Portalers. Trondheim had issues hearing us with well balanced levels, and we had issues hearing them when playing. So we figured trying fewer people playing and sending two instruments as one on the left channel and one on the right channel gave more flexibility. That gives each campus the ability to mix two instruments individually as a «multichannel» setup for a total of four (two by two) musicians.

Having some control over the sound, the next obstacle was musical rather than technical. As many of us know, it can be hard playing together for the first time. Especially when not physically together and having some audience. Not being that used to just jamming around, we quickly figured out that picking a song to play that all of us knew was probably a good idea. And it worked in a way. Here’s a snippet of All of Us, playing «All of Me».

<figure style="float: none">
   <iframe src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/video/2021_03_02_henrikhs_allofus.mp4" width="1024" height="576" frameborder="0" allowfullscreen></iframe>
   <figcaption>All of us playing "All Of Me"</figcaption>
</figure>

Still a little hard to keep track of tempo and navigate who’s playing what, but then again we all have a song to stick to. We kept on choosing songs and also did a kind of successful version of «It Ain’t Over» with Anders, Pedro, and Henrik in Oslo playing with Willie in Trondheim.

#### Processing a Player
Another technique we wanted to try was processing a player playing in Trondheim from Oslo and having a processing-based musical feedback between the locations. For this I, Henrik in Oslo, played with Lindsay in Trondheim. He played the piano and I processed it with the «COW» effect on the OP-1, which is a delay/modulation based effect. This was a jam based approach to playing and our experience with it was very good actually. Only being two performers with distinct differences in sound made the navigation quite easy as we both easily heard what the other one was doing. And only having one sound producing musician makes it easier to switch around keys and tempos as the processing will eventually follow.

<figure style="float: none">
   <iframe src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/video/2021_03_02_henrikhs_lindsay_pianocow.mp4" width="1024" height="576" frameborder="0" allowfullscreen></iframe>
   <figcaption>Lindsay playing piano through OP-1 COW</figcaption>
</figure>

The hardest part was doing the routing and figuring out the post/pre fader options on the mixer, but I will not consider this something to debate further as it’s simply a matter of figuring out the specifications and settings of the Midas PRO2.

#### Thoughts on Feedback
Lastly, these last weeks I wanted to fiddle around with EQ in an attempt to reduce feedback and resonant frequencies between NTNU and UiO. The mixer has the option to insert effects on the local master bus, so I wanted to put a graphical EQ on the sound on our side to experiment. Taking out narrow frequencies is a common way to reduce feedback between microphones and monitors using graphical EQs normally. Applying this on the Portal was, as are many things in this world, somewhat easier said than done. In the beginning it was quite easy getting rid of the highly resonant frequencies, but as they were lowered, other frequencies got the room to play and then they started resonating. Shortly the whole signal was EQ-ed to death, effectively just lowering the overall amplitude of the whole signal due to lowering almost all bands. So I started over with that in mind. The main issue was around 550 Hz, 800Hz and 260Hz, roughly, in addition to some hi mid and hi frequencies around 2,3kHz. It helped somewhat, but the received sound looses some body and feels a little thin when going hard on the EQ. This needs refining and tuning and a lot more testing. Maybe also measuring of the room and setting up all the EQs from scratch. It could be a great way to learn.
