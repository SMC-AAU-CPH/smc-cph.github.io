<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Musings with Bela | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Musings with Bela" />
<meta name="author" content="Jackson Goode" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A tale of accelerometers, knobs, an EEG and the attempt to tame sound with my mind. Follow along!" />
<meta property="og:description" content="A tale of accelerometers, knobs, an EEG and the attempt to tame sound with my mind. Follow along!" />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2020/10/16/musings-bela.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2020/10/16/musings-bela.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2020_10_16_jacksong_bela.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-10-16T10:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2020_10_16_jacksong_bela.jpg" />
<meta property="twitter:title" content="Musings with Bela" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jackson Goode"},"dateModified":"2020-10-16T10:00:00+00:00","datePublished":"2020-10-16T10:00:00+00:00","description":"A tale of accelerometers, knobs, an EEG and the attempt to tame sound with my mind. Follow along!","headline":"Musings with Bela","image":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2020_10_16_jacksong_bela.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2020/10/16/musings-bela.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Jackson Goode"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2020/10/16/musings-bela.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      Musings with Bela
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2020-10-16T10:00:00+00:00"
        itemprop="datePublished"
      >Oct 16, 2020 •
      </time>
         
      <a href="/authors/jacksongoode.html">Jackson Goode</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><p>For my project in the Interactive Music Systems course, I decided to work with a <a href="https://choosemuse.com/">portable EEG reader</a> and a <a href="https://bela.io/">Bela</a> coupled with an accelerometer and potentiometers. Little did I know how much of a challenge it is to join both software and hardware within an interactive package.</p>

<h1 id="inspiration">Inspiration</h1>

<p>Coming from a undergraduate degree in cognitive science, I’ve always wanted to work with (read hack) an <a href="https://en.wikipedia.org/wiki/Electroencephalography">electroencephalogram</a> (EEG) for some kind of artistic performance or instrument. While I have worked with a more traditional systems that require head-caps and conductive gel, I have never had the opportunity to test out some of the many different portable systems that have come out in the last decade. After reaching out to <a href="https://arj.no">Alexander Jensenius</a>, I was able to borrow a system from a researcher at RITMO - which I’ll cover later in the hardware section.</p>

<h2 id="artistic-examples">Artistic examples</h2>

<p>In addition to my personal interest in finding an artistic meeting point between cogsci and SMC, I was also inspired by a number of performances and musical systems that employed EEG technology.</p>

<p>The first of these was <a href="https://en.wikipedia.org/wiki/Alvin_Lucier">Alvin Lucier’s</a> “Music for Solo Performer” (1965) which was a landmark piece not only for its use of an EEG but sonification generally. Lucier had mapped the voltage potential from his electrodes into low-frequency tones that were able to excite percussive instruments in front of him.</p>

<figure>
    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/bIPU2ynqy2Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    <figcaption>Alvin Lucier's "Music for Solo Performer" (1965)</figcaption>
</figure>

<p>The second performance that offered insights in using EEG’s in a sonic environment was Ouzounian et al.’s Music for Sleeping &amp; Waking Minds (2011-2012). In their piece, they asked multiple participants to wear EEG sensors as they spent a night in a collective slumber. Over the course of the night, their brain waves (in passing through the various oscillatory states of sleep) were represented in sound and light.</p>

<figure>
    <iframe src="https://player.vimeo.com/video/30261043?byline=0&amp;portrait=0" width="560" height="315" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
    <figcaption>Participants sleeping for Music for Sleeping &amp; Waking Minds (2011-2012)</figcaption>
</figure>

<p>In addition to these, there were a number of other interesting takes on EEG sonification such as <a href="http://graceleslie.com/MoodMixer">MoodMixer</a> (Leslie and Mullen, 2011), a collaborative installation where two participants navigate a shared musical space via EEG as represented by a 2D visual space. Another implementation comes from the <a href="https://www.researchgate.net/publication/209435991_Disembodied_and_Collaborative_Musical_Interaction_in_the_Multimodal_Brain_Orchestra">Multimodal Brain Orchestra</a> (Le Grouz et al., 2010), a collection of musicians whose sheet music was generated on the spot as a product from a reading of their collective cognitive response. And recently, <a href="https://www.youtube.com/watch?v=n0T2uB-GLc8">Chris Chafe</a> worked on sonification of seizure data recorded from EEGs, providing an illumination of hidden neural activity.</p>

<p>However, in all of these examples, it’s not obvious what the sensor data is actually being mapped to - a confusing experience from both the audience as well as someone trying to find inspiration for an IMS of their own. For a much more clear framework on how one would go about building and evaluating an IMS, I turned to the literature.</p>

<h2 id="academic-support">Academic support</h2>

<p>Two articles held my interest during the time I spent conceptualizing and designing my system, the first from Birnbaum et al. In their article Towards a Dimension Space for Musical Devices, the authors lay out a visual representation for describing aspects of IMS (Birnbaum et al., 2005). They identify 7-axes that might characterize new interactive music systems and in parallel, provide some representative space of which to locate an author’s proposal for their own IMS.</p>

<ul>
  <li>Required Expertise</li>
  <li>Musical Control</li>
  <li>Feedback Modalities</li>
  <li>Degrees of Freedom</li>
  <li>Inter-actors</li>
  <li>Distribution in Space</li>
  <li>Role of Sound</li>
</ul>

<p>These principles were helpful as a means of comparing my proposed instrument against others but also for a class of features to focus on as I developed it. For Musings with Bela, this is how we might visualize its capacity as an instrument:</p>

<figure>
    <img src="/assets/image/2020_10_16_jacksong_dim_space.png" width="560px" />
    <figcaption>Musings with Bela's dimension space</figcaption>
</figure>

<p>The second paper, A Framework for the Evaluation of Digital Musical Instruments by O’Modhrain takes up a similar issue with the absence of well defined lenses through which we can consider, criticize and explain a musical instrument (O’Modhrain, 2011). O’Modhrain suggest that taking the perspective of not only a musician or designer when building an IMS, but also that of an audience member or even a manufacturer. These novel perspectives force an author to consider their instrument from angles that are not typically confronted until after the instrument has been built. In both articles, it is clear that building a musical interface is a project whose treatment must be considered with others in mind.</p>

<h1 id="hardware">Hardware</h1>

<p>The device actually made use of the breadboard it was wired to as a frame to hold and rotate the device. The Bela was placed in between the accelerometer and two knobs, allowing for it to easily sit in one’s hands. The idea was to keep the design uncomplicated as the EEG might require the performer to have their eyes closed.</p>

<div style="display: flex;">
    <figure style="flex-direction: column; flex-basis: 100%; flex: 1; margin: 1em;">
        <img src="/assets/image/2020_10_16_jacksong_bela.jpg" />
        <figcaption>Bela and friends</figcaption>
    </figure>
    <figure style="flex-direction: column; flex-basis: 100%; flex: 1; margin: 1em;">
        <img src="/assets/image/2020_10_16_jacksong_muse.jpg" />
        <figcaption>The Muse</figcaption>
    </figure>
</div>

<p>A <a href="https://choosemuse.com/">Muse</a> (2016) portable eeg headband, graciously borrowed from RITMO, was another major hardware device incorporated within my IMS. I had read through my preliminary research that this device might be easily hackable. Imagine my sadness after finding out all developer resources for the device were discontinued (ARJ you liar!). Unbroken, I pushed forward and ended up modifying a completely unknown Python package to finally interface with the device.</p>

<p>Nevertheless, the device’s specs are quite impressive with 4 electrodes recording at 256Hz and an all-day battery life (no joke). Unfortunately, the fact that the device streamed through Bluetooth meant that my laptop would necessarily be involved (I wouldn’t <em>dare</em> attempt it on the Bela (Okay, maybe if I had another week!)).</p>

<h1 id="software">Software</h1>

<h2 id="interpolating-between-tables-with-an-accelerometer">Interpolating between tables with an accelerometer</h2>

<p>At the core of my system was a method for interpolating between short audio grains. Audio files were read into an array of 1024 samples and these arrays were then interpolated using the external <a href="">iemmatrix</a>. More typical methods of reading through arrays would be to step through each index and read the sample, apply whatever operation you wanted and then store it. In my case, however, I wanted to tie the accelerometer to degree each sound file is interpolated into one another (via arrays) which makes it challenge to read through these arrays sequentially when the sample rate of change needs to be very fast. iemmatrix instead, allows for operations to take place on the array as a whole (like <a href="https://www.geeksforgeeks.org/vectorization-in-python/">numpy vectorization</a>) meaning this is a much more efficient method of morphing between these arrays.</p>

<figure>
    <img class="no-shadow" src="/assets/image/2020_10_16_jacksong_intrp.png" width="560px" />
    <figcaption>A shot of the main matrix operation sub-patch</figcaption>
</figure>

<p>Upon reflection, another alternative would be to get two readings, do the matrix operations, and slide between them with a [line] object. As I was looking into this, this is an external (list-abs) that allows for linear interpolation between lists. However, this might be a slightly more costly object to use - perhaps a combination of both techniques would have worked best.</p>

<p>The two physical knobs control an oscillator to read the resultant table (a morphed sound grain) into the DAC. These knobs are also read at audio-rate but the operations they control are far less complicated. In Musings with Bela, these knobs serve as tuners for the synth that can explored (sonically) by rotating the device.</p>

<h2 id="reading-arrays-and-remaining-calm">Reading arrays and remaining calm</h2>

<p>Finally, the last piece to my glorious IMS puzzle, the Muse! As I mentioned, this device was tricky, thorny, and a general struggle to work with, especially considering I had to set the Bela up as a WiFi hot-spot to pass the samples from the Muse, to my PC and then off to the Bela.</p>

<p>Another major piece of working with the Muse was actually testing to see the behavior of the electrode readings, if they are consistent, their fluctuations, and whether or not I would be able to reliably reduce the noise and relative intensity. I made a subpatch to test for this reason, allowing me to record and playback samples from the Muse even without its connection.</p>

<figure>
    <img src="/assets/image/2020_10_16_jacksong_pd_eeg.webp" />
    <figcaption>Data from the Muse</figcaption>
</figure>

<p>Musings with Bela takes this EEG stream and modulate the amplitude of the read table so that, in theory, a wandering, active mind would lead to a disrupted synth. The configuration was technical to say the least and, in retrospect, something I wish I had tackled earlier in the building process so I could use the EEG signals in a more complex mapping.</p>

<h1 id="reflections">Reflections</h1>

<p>Building an IMS is a whirlwind of an experience and one that is especially difficult to achieve in two weeks. Working with hardware and software turned out to double the time I expected any individual task would take. However, I feel like I had successfully built an interesting system that touched on my history in cognitive science and applied it within this an acousmatic environment.</p>

<h2 id="here-is-my-short-final-performance-for-smc4045">Here is my short, final performance for SMC4045.</h2>

<figure>
    <iframe width="800" height="450" src="https://www.youtube-nocookie.com/embed/gEq9EnWrApc?start=901" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    <figcaption>Musings with Bela</figcaption>
</figure>

<h2 id="and-my-final-presentation-can-be-found-below-as-well">And my final presentation can be found below as well!</h2>

<iframe src="https://slides.com/jacksongoode/musings-bela/embed" width="800" height="450" scrolling="no" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>

<h1 id="references">References</h1>

<p>Birnbaum, David, et al. <em>Towards a Dimension Space for Musical Devices</em>. 2005.</p>

<p>Fan, Yuan-Yi, and F. Myles Sciotto. ‘BioSync: An Informed Participatory Interface for Audience Dynamics and Audiovisual Content Co-Creation Using Mobile PPG and EEG.’ <em>NIME</em>, 2013, pp. 248–251.</p>

<p>Hamano, Takayuki, et al. ‘Generating an Integrated Musical Expression with a Brain-Computer Interface.’ <em>NIME</em>, 2013, pp. 49–54.</p>

<p>Le Groux, Sylvain, et al. ‘Disembodied and Collaborative Musical Interaction in the Multimodal Brain Orchestra.’ <em>NIME</em>, 2010, pp. 309–314.</p>

<p>Leslie, Grace, and Tim R. Mullen. ‘MoodMixer: EEG-Based Collaborative Sonification.’ <em>NIME</em>, Citeseer, 2011, pp. 296–299.</p>

<p>O’Modhrain, Sile. ‘A Framework for the Evaluation of Digital Musical Instruments’. <em>Computer Music Journal</em>, vol. 35, Mar. 2011, pp. 28–42. <em>ResearchGate</em>, doi:<a href="https://doi.org/10.1162/COMJ_a_00038">10.1162/COMJ_a_00038</a>.</p>

<p>Ouzounian, Gascia, et al. ‘To Be inside Someone Else’s Dream: On Music for Sleeping &amp; Waking Minds’. <em>New Interfaces for Musical Expression (NIME 2012)</em>, 2012, pp. 1–6.</p>

<p>Parvizi, Josef, et al. ‘Detecting Silent Seizures by Their Sound’. <em>Epilepsia</em>, vol. 59, no. 4, 2018, pp. 877–84. <em>Wiley Online Library</em>, doi:<a href="https://doi.org/10.1111/epi.14043">10.1111/epi.14043</a>.</p>

<p>Straebel, Volker, and Wilm Thoben. ‘Alvin Lucier’s Music for Solo Performer: Experimental Music beyond Sonification’. <em>Organised Sound</em>, vol. 19, no. 1, Cambridge University Press, Apr. 2014, pp. 17–29. <em>Cambridge University Press</em>, doi:<a href="https://doi.org/10.1017/S135577181300037X">10.1017/S135577181300037X</a>.</p>

<p>Wu, Dan, et al. ‘Scale-Free Brain Quartet: Artistic Filtering of Multi-Channel Brainwave Music’. <em>PloS One</em>, vol. 8, no. 5, 2013, p. e64046. <em>PubMed</em>, doi:<a href="https://doi.org/10.1371/journal.pone.0064046">10.1371/journal.pone.0064046</a>.</p>
</div>

  

  <a class="u-url" href="/interactive-music/2020/10/16/musings-bela.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
