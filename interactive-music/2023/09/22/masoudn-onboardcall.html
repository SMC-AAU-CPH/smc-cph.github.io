<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Review of On Board Call: A Gestural Wildlife Imitation Machine | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Review of On Board Call: A Gestural Wildlife Imitation Machine" />
<meta name="author" content="Masoud Niknafs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Critical Review of On Board Call: A Gestural Wildlife Imitation Machine" />
<meta property="og:description" content="Critical Review of On Board Call: A Gestural Wildlife Imitation Machine" />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/09/22/masoudn-onboardcall.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/09/22/masoudn-onboardcall.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_onboard_cover.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-09-22T12:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_onboard_cover.png" />
<meta property="twitter:title" content="Review of On Board Call: A Gestural Wildlife Imitation Machine" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Masoud Niknafs"},"dateModified":"2023-09-22T12:00:00+00:00","datePublished":"2023-09-22T12:00:00+00:00","description":"Critical Review of On Board Call: A Gestural Wildlife Imitation Machine","headline":"Review of On Board Call: A Gestural Wildlife Imitation Machine","image":"https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_onboard_cover.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/09/22/masoudn-onboardcall.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Masoud Niknafs"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/09/22/masoudn-onboardcall.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      Review of On Board Call: A Gestural Wildlife Imitation Machine
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2023-09-22T12:00:00+00:00"
        itemprop="datePublished"
      >Sep 22, 2023 •
      </time>
         
      <a href="/authors/masoudniknafs.html">Masoud Niknafs</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><h2 id="review-of-on-board-call-a-gestural-wildlife-imitation-machine">Review of On Board Call: A Gestural Wildlife Imitation Machine</h2>

<p>The <a href="https://nime.pubpub.org/pub/uofmcznd/release/1">On Board Call</a> introduced in NIME  2022 is a handheld musical device designed to mimic and engage with wildlife sounds, such as bird or animal calls. Instead of just playing pre-recorded sounds, it uses microprocessor-based synthesis and sensors like an accelerometer and force sensor to allow users to interactively modify and perform with the sounds in real-time. Developed as part of the PLACE art-science project at Griffith University, its goal is to enhance appreciation for the eco-acoustic diversity of nature. The device is cost-effective and easily assembled from off-the-shelf components, making it ideal for community workshops focused on active listening and connecting with natural environments.</p>

<figure style="float: none">
   <img src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_onboard.jpg" width="60%" />
   <figcaption>On Board call System(Photo from NIME website)</figcaption>
</figure>

<h1 id="hardware">Hardware:</h1>
<p>The musical interface uses an <a href="https://en.wikipedia.org/wiki/ESP8266">ESP8266</a>microprocessor and an Adafruit <a href="https://www.adafruit.com/product/3006">MAX98357A</a> audio board, powered by a battery case. The 6050-accelerometer detects gestures like pitch and yaw, communicating via the <a href="https://www.circuitbasics.com/basics-of-the-i2c-communication-protocol/">12C protocol</a>. Accelerometer data adjusts audio’s frequency and timbre, while a force sensor regulates volume. A rotary encoder with a switch allows volume and algorithm adjustments. The Adafruit board links to a loudspeaker for sound output. Components are mounted on a compact  PCB, designed for durability and potential future adaptations.</p>

<figure style="float: none">
   <img src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_on-_board.jpg" width="60%" />
   <figcaption>On Board Call PCB</figcaption>
</figure>

<iframe width="560" height="315" src="https://www.youtube.com/embed/iBTBPpaSGi8?si=EszBRAHb93kD76T4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h1 id="software-and-mappings">Software and Mappings:</h1>
<p>The software allows for the replication of calls with multiple sound components by duplicating the architecture. Presets define synthesis parameters for specific animals, but real-time pitch and timbre adjustments are performer-driven. Some presets automate rapid envelope repetitions to mimic certain call effects. The software, crafted in the Arduino IDE, utilizes the <a href="https://sensorium.github.io/Mozzi/">Mozzi</a> library for sound generation.
The software design began by analyzing calls of different animals from the Oxley Creek Common site. Spectral analysis highlighted the variations in pitch and timbre. This examination revealed that these sounds could be emulated using basic frequency modulation methods.</p>

<p>In the context of the Call software for the interactive music system, the mapping relationships appear to be oriented towards optimizing user interaction and simplifying synthesis architecture(Drummond, 2009).According to Hunt and Krik, and Miranda and wanderley. (Hunt and Kirk 2000; Miranda and Wanderley 2006), we can evaluate the Call software’s mapping as follows:</p>

<ol>
  <li>
    <p>One-to-One Mappings: This is evident when specific gestures or positions of the device correspond directly to certain synthesis parameters. For instance, the device’s resting state has established values for pitch and timbre. Similarly, the rotary encoder’s default function is to control the master volume.</p>
  </li>
  <li>
    <p>One-to-Many Mappings: The accelerometer’s x and y axes controlling both pitch and timbre can be considered an example of this. A single tilt or movement impacts multiple synthesis parameters simultaneously, enriching the resultant sound. Such a design decision helps in minimizing complexities that might arise with individual controls for each parameter.</p>
  </li>
  <li>
    <p>Many-to-One Mappings: Loudness control in the software is an example, as it takes input both from the device’s position (orientation) and the force sensor, i.e., pressure applied by the user.</p>
  </li>
  <li>
    <p>Many-to-Many Mappings: While not explicitly stated, the rotary encoder’s multifunctionality (adjusting synthesis parameters, selecting algorithm presets, etc.) suggests that its rotations and presses can influence a variety of parameters, making it a many-to-many mapping interface.</p>
  </li>
</ol>

<figure style="float: none">
   <img src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_09_20_masoudn_on-.png" width="60%" />
   <figcaption>On Board Call interaction diagram with a simple two-operator FM synthesis architecture (Photo from NIME website)</figcaption>
</figure>

<p>The use of sigmoid curves to provide stability near the device’s resting state indicates a deliberate effort to smoothen real-time mapping. According to Wanderley gesture data aquisation is “direct” and “alternate” in this case where sensors monitor the performer’s actions, capturing specific gesture features like pressure, displacement, and acceleration, with each variable typically detected by a distinct sensor, and alternate in a manner that it does not resemble any instrument (Miranda et al,.2006).</p>

<h1 id="trials-and-evaluation">Trials and Evaluation:</h1>

<p>As outlined in the project paper, the design was refined through numerous iterations and prototypes in both software and hardware. Field trials were also conducted with professional musicians in natural settings, primarily in ensemble setups alongside acoustic instruments during imitation and listening sessions. The focus of these trials was primarily on the design’s durability. However, the paper does not address the feedback received or any interaction with the musician group.</p>

<p>Furthermore, the paper notes consultations with birding communities. These sessions encompassed playing, comparisons, discussions, and analysis. The authors contend that birders, as expert wildlife listeners, offered invaluable insights that influenced the synthesis and gestural control aspects of the device’s design.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/uKgLrrI-MEU?si=eZi9h3GX4MSpXbFM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<h1 id="usabilty-and-engagement">Usabilty and Engagement:</h1>
<p>In contrast to prior systems that utilize fixed spectromorphologies, parameters, and envelopes, the approach discussed here ventures into the realm of dynamic spectral interaction. The On Call device, leveraging its microprocessor PCB audio system for sound synthesis, places a premium on user-friendliness and ease of use, even if it means compromising on imitative accuracy. Holland et al. explored the question of whether musical interaction should necessarily be simple (Holland et al., 2013). Emulation, as defined by imitative accuracy in this project, is brought into focus by Kesilar, who examines the challenge of addressing a well-known issue which in this case is imatation of wildlife tones(Keisler, 2001). This prompts an inquiry: Does this design approach risk diminishing user engagement? McDermott and peers suggest that long-lasting engagement often stems from activities that present initial challenges to novices(McDermott et al., 2013).</p>

<h1 id="sources">Sources</h1>

<ul>
  <li>
    <p>Brown, A. R. (Ed.). (2022). On Board Call: A Gestural Wildlife Imitation Machine. NIME 2022. https://doi.org/10.21428/92fbeb44.71a5a0ba</p>
  </li>
  <li>
    <p>Drummond, J. (2009). Understanding Interactive Systems. Organised Sound, 14(2), 124-133. https://doi.org/10.1017/S1355771809000235</p>
  </li>
  <li>
    <p>Holland, S., Wilkie, K., Mulholland, P., &amp; Seago, A. (2013). Music Interaction: Understanding Music and Human-Computer Interaction. In S. Holland, K. Wilkie, P. Mulholland, &amp; A. Seago (Eds.), Music and Human-Computer Interaction (Springer Series on Cultural Computing). Springer, London. https://doi.org/10.1007/978-1-4471-2990-5_1</p>
  </li>
  <li>
    <p>Hunt, A., &amp; Kirk, R. (2000). Mapping Strategies for Musical Performance. In M. M. Wanderley &amp; M. Battier (Eds.), Trends in Gestural Control of Music. IRCAM–Centre Pompidou.</p>
  </li>
  <li>
    <p>Keislar, D. (2011). A Historical View of Computer Music Technology. In R. T. Dean (Ed.), The Oxford Handbook of Computer Music (Oxford Handbooks online edition). Oxford Academic. https://doi.org/10.1093/oxfordhb/9780199792030.013.0002</p>
  </li>
  <li>
    <p>McDermott, J., Gifford, T., Bouwer, A., &amp; Wagy, M. (2013). Should Music Interaction Be Easy?. In S. Holland, K. Wilkie, P. Mulholland, &amp; A. Seago (Eds.), Music and Human-Computer Interaction (Springer Series on Cultural Computing). Springer, London. https://doi.org/10.1007/978-1-4471-2990-5_2</p>
  </li>
  <li>
    <p>Miranda, E. R., &amp; Wanderley, M. (2006). New Digital Musical Instruments: Control and Interaction Beyond the Keyboard. A-R Editions.</p>
  </li>
</ul>

</div>

  

  <a class="u-url" href="/interactive-music/2023/09/22/masoudn-onboardcall.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
