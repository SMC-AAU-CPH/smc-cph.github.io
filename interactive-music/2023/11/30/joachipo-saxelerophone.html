<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The Saxelerophone: Demonstrating gestural virtuosity | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="The Saxelerophone: Demonstrating gestural virtuosity" />
<meta name="author" content="Joachim Poutaraud" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A hyper-instrument tracking data from a 3-axis accelerometer and a contact microphone to create new interactive sounds for the saxophone." />
<meta property="og:description" content="A hyper-instrument tracking data from a 3-axis accelerometer and a contact microphone to create new interactive sounds for the saxophone." />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/11/30/joachipo-saxelerophone.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/11/30/joachipo-saxelerophone.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_11_26_joachipo_saxelerophone.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-30T08:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_11_26_joachipo_saxelerophone.jpg" />
<meta property="twitter:title" content="The Saxelerophone: Demonstrating gestural virtuosity" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Joachim Poutaraud"},"dateModified":"2023-11-30T08:00:00+00:00","datePublished":"2023-11-30T08:00:00+00:00","description":"A hyper-instrument tracking data from a 3-axis accelerometer and a contact microphone to create new interactive sounds for the saxophone.","headline":"The Saxelerophone: Demonstrating gestural virtuosity","image":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_11_26_joachipo_saxelerophone.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/11/30/joachipo-saxelerophone.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Joachim Poutaraud"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/interactive-music/2023/11/30/joachipo-saxelerophone.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      The Saxelerophone: Demonstrating gestural virtuosity
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2023-11-30T08:00:00+00:00"
        itemprop="datePublished"
      >Nov 30, 2023 •
      </time>
         
      <a href="/authors/joachimpoutaraud.html">Joachim Poutaraud</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><p>“Knowing the game” is often necessary when it comes to evaluating live performances, especially if it turns out that the performer in front of you is playing one of those totally wacky Interactive Music Systems (IMS)! In the <a href="https://www.nime.org/">NIME</a> community , it’s quite common for these IMS to reflect a “<em>short-lived expression of individualism</em>” rather than a design intended for a wider audience (<a href="https://aaltodoc.aalto.fi/items/acf35069-fdae-4e0d-ae2c-b195ac6f51d0">Vasquez et al., 2017</a>). In fact, this is essentially due to their very nature, as IMS have the unfortunate tendency to limit the <em>demonstration of virtuosity</em> associated with acoustic instruments, since most of these systems operate a brutal separation between human action (i.e. gesture) and the sound production system.</p>

<p>Well, in the <a href="https://www.nime.org/">NIME</a> community there’s even talk of a virtuosity crisis (<a href="https://escholarship.org/uc/item/8v0022bd">Dobrian and Koppelman, 2006</a>), and there’s actually a fair amount of concern about questions that deal with how IMS performances can be meaningful, perceptible and useful (<a href="https://www.jstor.org/stable/3681975?casa_token=D6QYoRqhO90AAAAA%3Aebt6wSoyVNFfS4ZF0Ow7nBKzh33sJyI5PwUYQyMRe7UEenMJpFS30q2kR7Fr1RPsZBqhizG9jdnI1umBY5uhrIClBKSTa5PGzmPp3SrUIuHzrkyD4GH5">Wessel and Wright, 2002</a>, <a href="https://www.tandfonline.com/doi/abs/10.1076/jnmr.32.3.239.16866?casa_token=8stJ2rgnSaIAAAAA:yP6aek1Yt8exeN4QZGV5z5J_d4Yls-FdcAOlnWndrL4KfrsU3EIAdVSk8s0lR5-nM_J0WGDNW4vgIg">Schloss, 2003</a>). It’s true that the concept of <em>virtuosity</em> in the field of IMS has often been associated with a large sonic palette, via the manipulation of synthesizers or the use of a whole host of samples (<a href="https://d1wqtxts1xzle7.cloudfront.net/22468080/kim_cascone_laptop_music_v2-libre.pdf?1390867287=&amp;response-content-disposition=inline%3B+filename%3DLaptop_music_counterfeiting_aura_in_the.pdf&amp;Expires=1700760811&amp;Signature=UfdGLvSOaSLuuq2HS6MghQbO-nUIG0WnyTuN9RNiG6WkiHSZIh5blNW~UIdAEFowhu15FSQQxig5dB40YTAmhrVruA-66dl~6dVO0rXzG4dFmrNHw1Mhn6yhNcrzLh-4cJBin~Yo4sjEH8bm6lpemt-h~EBdhPJGSBxz-8nC7ad63iZxDf1vbRw56GHrobWmU1VixDaPq2RVbrR2HSgKIKXq0q9hCAWEyWG9-Xd9EUNagwbxvmBUAjmpIeUFfsRUoeD19VTPDgGD5Cq-3jpTziO8fZdZXTF~DaQTyxC4C4ZvmXscg4pMYrkD8-WFk1sw3b3W-oT18n7mMv-4Go2XPw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">Cascone, 2002</a>), that can be easily manipulated by the performer, without having to worry too much about the gestures involved (<a href="https://nime.pubpub.org/pub/f1ueovwv/release/1">West et al., 2021</a>). And that’s where the problem lies! Because, in order to recreate a relationship between human action and the sound production system, shouldn’t we first and foremost be interested in gesture as a sound-generating function?</p>

<h1 id="the-saxelerophone">The Saxelerophone</h1>
<p><br />
Well, I think so, and that’s why I created the Saxelerophone. This IMS is designed to take account of the performer’s <em>bandwidth</em>, given that “<em>some players have spare bandwidth, some do not</em>” (<a href="https://link.springer.com/chapter/10.1007/978-3-319-47214-0_1">Cook, 2017</a>), but also of the visual relationship between gesture and sound in a live performance. In this sense, the Saxelerophone’s main objective is to improve the <em>demonstration of virtuosity</em>, which often tends to be misinterpreted by the public when it comes to new musical instruments (<a href="https://aaltodoc.aalto.fi/items/acf35069-fdae-4e0d-ae2c-b195ac6f51d0">Vasquez et al., 2017</a>).</p>

<figure style="float: none">
   <img src="/assets/image/2023_11_20_joachipo_saxelerophone.jpg" alt="The Saxelerophone." width="100%" />
   <figcaption>The Saxelerophone. Left: Soprano saxophone (Selmer Super Action 80 Series II) with sensors on the mouthpiece connected to a Bela board. Right (top): ADXL337 3-axis digital accelerometer sensor positioned above the contact microphone. Right (bottom): Contact microphone based on piezo material positioned on the saxophone’s ligature.</figcaption>
</figure>

<p>To achieve this, I conceived the Saxelerophone as a hyper-instrument (i.e. added additional sensors to the saxophone), “<em>to give extra power and finesse to virtuosic performers</em>” (<a href="https://cir.nii.ac.jp/crid/1573950398868759680">Machover and Chung, 1989</a>). On the one hand, it’s a simple, flexible system consisting of a contact microphone and a three-axis digital accelerometer, designed to be mounted on any reed instrument fitted with a ligature. On the other hand, it’s a system based on complex gestural control of sound synthesis, using robust machine-learning methods to learn static regression mappings, enabling the construction of a new expressive and creative sound space for developing gestural virtuosity.</p>

<p>The code, design files and technical documentation to replicate the system are available at the following address: <a href="https://github.com/joachimpoutaraud/saxelerophone">https://github.com/joachimpoutaraud/saxelerophone</a>.</p>

<h2 id="gestural-control-of-sound-synthesis">Gestural control of sound synthesis</h2>

<p>To saxophonists, it’s relatively easy to move their instrument around in space when playing. In fact, the smaller the saxophone, the easier it is, and that’s quite common to see this kind of demonstration at live performances.</p>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/v3EeELhgAlI?si=UxWIw5GLIUm22yC0" title="Kenny Garrett Quintet - Hargrove (live @Festival Jazz en Tête)" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>So I thought it would be interesting to use the <em>musical gestures</em> of saxophonists, which have a certain capacity to visually <em>accompany</em> sound, in the sense that they are gestures in response to sound. These gestures have already been described as “<em>sound-accompanying</em>” (<a href="https://books.google.no/books?hl=en&amp;lr=&amp;id=lHaMAgAAQBAJ&amp;oi=fnd&amp;pg=PA12&amp;dq=A.+R.+Jensenius+and+M.+M.+Wanderley.+Musical+gestures:+Concepts+and+methods+in+research.+In+Musical+gestures,+pages+24%E2%80%9347.+Routledge,+2010.&amp;ots=9tN20u9B7G&amp;sig=YmoZFemJy-_nf2USUG2fZ9_sptc&amp;redir_esc=y#v=onepage&amp;q&amp;f=false">Jensenius et al., 2010</a>) or “<em>sound-tracing</em>” (<a href="https://www.duo.uio.no/handle/10852/26899">Godøy et al., 2006</a>) gestures.</p>

<p>Three main objectives were defined for demonstrating gestural virtuosity with the Saxelerophone.</p>

<h3 id="1-audio-sensing">1. Audio sensing</h3>

<p>For audio sensing, the aim was to collect acoustic information specific to the instrument with a contact microphone, so that it could be reused to generate new sounds. Here, I was interested in the fundamental frequency of the notes produced by the instrument, to be converted as the frequency of the carrier oscillator within the audio spectrum. Note that the contact microphone was also used to amplify the acoustic sound of the saxophone.</p>

<h3 id="2-gesture-sensing">2. Gesture sensing</h3>

<p>Next, a three-axis digital accelerometer was used to determine the saxophone’s orientation and changes in movement.</p>

<figure style="float: none">
   <img src="/assets/image/2023_11_20_joachipo_adxl337.jpg" alt="ADXL337 3-axis digital accelerometer." width="60%" />
   <figcaption>ADXL337 3-axis digital accelerometer.</figcaption>
</figure>

<p>It was this sensor that first and foremost enabled me to define a physical relationship between the performer’s <em>sound-accompanying</em> gestures and sound synthesis control parameters (i.e. mapping). The mapping of gestures to sound synthesis parameters was then performed using machine learning. To do this, a regression algorithm was trained using an ANN framework for Pure Data called <a href="https://github.com/alexdrymonitis/neuralnet">neuralnet</a> to create a new sound space in which the performer could navigate to generate new interactive sounds. A schematic representation of the Saxelerophone’s mappings is shown in the diagram below.</p>

<figure style="float: none">
   <img src="/assets/image/2023_11_20_joachipo_mappings.jpg" alt="Saxelerophone's mappings." width="60%" />
   <figcaption>Saxelerophone's mappings.</figcaption>
</figure>

<h3 id="3-motion-sensing">3. Motion sensing</h3>

<p>Finally, accelerometer data was integrated to estimate the instrument’s velocity. It is this last variable that allowed me to demonstrate a certain gestural virtuosity, since it enabled me to control the natural volume of the saxophone according to the volume of the synthesized sound. As the volume of the acoustic sound is inversely proportional to the synthesized sound, this means that the faster the instrument is moved in space, the more the sound will be synthesized, and vice versa. This allows the performer to play with two different musical palettes (acoustic vs. synthesized), depending on the speed of change of its position in relation to time.</p>

<h1 id="personal-reflections">Personal Reflections</h1>
<p><br />
As the designer of this instrument, I feel that the challenge of developing an instrument to demonstrate a new gestural virtuosity for the saxophone has on the whole been successful. The main technical challenges were to define the right frequency variation of the resistor-capacitor circuit (RC circuit) for use with the contact microphone, and to design a system that was flexible and adaptable to any reed instrument fitted with a ligature. After conducting a quick preliminary study involving 4 participants on the question of the audience perspective, the results obtained were largely positive. This confirmed my position on the subject, although the results were not compared to another IMS, nor to a different prototype version of the Saxelerophone.</p>

<p>As a performer of this instrument, I think first of all that a new approach to writing could be developed for this instrument, taking into account the performer’s gestures on the score. In addition, I think that in-depth work on the saxophone’s playing modes could be envisaged to deepen learning and engagement with the instrument. For the time being, the Saxelerophone relies on a single space for personal sound creation. Although it is possible to create new sound spaces ad infinitum, it would be beneficial to add new input variables related to the instrument’s own playing modes (percussive, blown, sung or multiphonic sounds) when training the model. This would give the performer greater expressiveness and a wider variety of sounds to match his or her virtuoso abilities.</p>

<h2 id="performing-with-the-saxelerophone">Performing with the Saxelerophone</h2>

<iframe width="100%" height="500" src="https://www.youtube.com/embed/xH90NDN7JsQ?si=q3m7FXBLyI6kskkb" title="Performing live with the Saxelerophone" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><strong>References</strong>
<br /></p>
<ul>
<li><font size="3"><p>Vasquez, J. C., Tahiroglu, K., &amp; Kildal, J. (2017). Idiomatic composition practices for new musical instruments: context, background and current applications. In NIME (pp. 174-179).</p></font></li>

<li><font size="3"><p>Dobrian, C., &amp; Koppelman, D. (2006). The ‘E’in NIME: musical expression with new computer interfaces.</p></font></li>

<li><font size="3"><p>Wessel, D., &amp; Wright, M. (2002). Problems and prospects for intimate musical control of computers. Computer music journal, 26(3), 11-22.</p></font></li>

<li><font size="3"><p>Schloss, W. A. (2003). Using contemporary technology in live performance: The dilemma of the performer. Journal of New Music Research, 32(3), 239-242.</p></font></li>

<li><font size="3"><p>Cascone, K. (2002). Laptop music-counterfeiting aura in the age of infinite reproduction. Parachute, 52-59.</p></font></li>

<li><font size="3"><p>West, T., Caramiaux, B., Huot, S., &amp; Wanderley, M. M. (2021, May). Making mappings: Design criteria for live performance. In NIME 2021. PubPub.</p></font></li>

<li><font size="3"><p>Cook, P. (2017). 2001: Principles for designing computer music controllers. A NIME Reader: Fifteen years of new interfaces for musical expression, 1-13.</p></font></li>

<li><font size="3"><p>Machover, T. &amp; Chung, J. (1989). Hyperinstruments: Musically Intelligent and Interactive Performance and Creativity Systems.</p></font></li>

<li><font size="3"><p>A. R. Jensenius and M. M. Wanderley. Musical gestures: Concepts and methods in research. In Musical gestures, pages 24–47. Routledge, 2010.</p></font></li>

<li><font size="3"><p>R. I. Godøy, E. Haga, and A. R. Jensenius. Exploring music-related gestures by sound-tracing: A preliminary study. 2006.</p></font></li>
</ul>
</div>

  

  <a class="u-url" href="/interactive-music/2023/11/30/joachipo-saxelerophone.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
