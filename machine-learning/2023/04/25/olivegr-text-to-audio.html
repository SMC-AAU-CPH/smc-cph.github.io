<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Generating Video Game SFX with AI | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Generating Video Game SFX with AI" />
<meta name="author" content="Oliver Getz" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A first look at text-to-audio sound effect generation for video games." />
<meta property="og:description" content="A first look at text-to-audio sound effect generation for video games." />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2023/04/25/olivegr-text-to-audio.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2023/04/25/olivegr-text-to-audio.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_04_25_olivegr_audioldm_tta.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-04-25T18:12:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_04_25_olivegr_audioldm_tta.jpg" />
<meta property="twitter:title" content="Generating Video Game SFX with AI" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Oliver Getz"},"dateModified":"2023-04-25T18:12:00+00:00","datePublished":"2023-04-25T18:12:00+00:00","description":"A first look at text-to-audio sound effect generation for video games.","headline":"Generating Video Game SFX with AI","image":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2023_04_25_olivegr_audioldm_tta.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2023/04/25/olivegr-text-to-audio.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Oliver Getz"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2023/04/25/olivegr-text-to-audio.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      Generating Video Game SFX with AI
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2023-04-25T18:12:00+00:00"
        itemprop="datePublished"
      >Apr 25, 2023 •
      </time>
         
      <a href="/authors/olivergetz.html">Oliver Getz</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><p>Early 2023, Hugging Face released a pipeline for <a href="https://github.com/haoheliu/AudioLDM">AudioLDM</a>. What this means is that audio generation with AI became readily accessible to everyone, with low setup times. Text-to-audio is, at this very moment, right at our fingertips! Curious about its usage in game audio, I set out to explore its current capabilities and limitations.</p>

<h1 id="ai-sfx-generation-setup-guide">AI SFX Generation Setup Guide</h1>
<p>Getting up and running took a bit more effort than I anticipated due to Python packaging conflicts and GPU issues. If you are having trouble with pytorch and GPUs, you can follow my <a href="http://https://SMC-master.github.io/machine-learning/2023/04/25/olivegr-pytorch-gpu.html">setup guide</a>. If you still have issues using CUDA, do like me and switch from full precision (torch.float32) to half precision (torch.float16) like so:</p>

<pre>
  <code>
    from diffusers import AudioLDMPipeline
    pipe = AudioLDMPipeline.from_pretrained("cvssp/audioldm", torch_dtype=torch.float16)
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    pipe = pipe.to(device)
  </code>
</pre>

<p>If you’re wondering: yes, this can negatively influence your results, but not enough for it to be a real issue.</p>

<h1 id="generating-sfx-with-ai">Generating SFX With AI</h1>
<p>The prompts used were widely different for the sake of exploring the versatility of the AI. The authors suggest sticking to sounds from real life, but—lazy as I am—I asked directly for video game sounds as well. 20 sounds were generated for my first experiment, and here are the parameters I used:</p>

<pre>
  <code>
  audio = pipe(prompt,
               num_inference_steps=15,      # This is the amount of denoising steps. Higher is cleaner, but makes generating take longer.
               audio_length_in_s=4.0        # The length of the generated audio. Default is 5, but for a one-shot sfx, you don’t need more than 3-4 seconds. This will also speed up generation on CPUs.
               num_waveforms_per_prompt=1,  # How many files to generate.
               guidance_scale = 3,          # How much to conform to your prompt. Higher is more accurate, but introduces more noise.
               #negative_prompt="music"     # Elements you want to avoid in the resulting sound.
              ).audios[0]
  </code>
</pre>

<p>Results were mixed. For a sound to be usable as is in a video game, it will more often than not need to be isolated, meaning no background noise or overlapping sounds. Some prompts gave me multiple sounds of the same type layered on top of each other:</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_hammer_2.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "hammering a nail into wood"</figcaption>
</figure>

<p>Others contained nothing but noise:</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_construction.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "high quality construction site sfx, slight compression"</figcaption>
</figure>

<p>This was mostly the case for “imaginary” sounds with no real-world references, like a dragon. I can imagine the data set for dragon sounds is comparatively quite small.</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_dragon.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "a big dragon's roar"</figcaption>
</figure>

<p>On the other hand, many of the foley-like sounds were as clean as I could ever have hoped for. Each sound took 3-4 minutes to generate on the CPU, and mere seconds on my GPU after additional testing.</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_hammer_cinematic.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "a nail being hammered into wood"</figcaption>
</figure>

<p>Adding the word “cinematic” to the prompt generated similar sounds, but with more bass.</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_hammer.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "cinematic hammering a nail into wood"</figcaption>
</figure>

<p>The model seems either somewhat biased toward music, or infer some musical meaning from certain adjectives. By this I mean that no prompts for music generated sound effects, but 2-3% of prompts for non-musical sounds generated synthesized chords, even with a negative “music” prompt.</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_footstep.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "footstep in wet sand"</figcaption>
</figure>

<p>More can probably be done to avoid generating music-like content, but I figured it wasn’t worth spending time on. I simply discarded any files with musical content, but who knows, maybe you discover some new sounds you like.</p>

<p>Asking for 90s video game sounds provided some interesting results. I specified 90s, because the style at the time was limited by hardware but a lot of pre-processing could be done to make sounds more expressive, like crazy pitch envelopes. AudioLDM is capable of making abstract sound effects equally expressive.</p>

<figure>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_vgs.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>Prompt: "90s video game sound effect"</figcaption>
</figure>

<h1 id="sacred-gems">Sacred Gems</h1>
<p>One of my current projects is designing sound and music for a 2D bullet hell game called Sacred Gems. Aesthetically, it takes a lot of inspiration from 80’s anime and we wanted similar elements to be featured in the soundscape. Since some of the sounds can be a bit noisy, and as far as I can tell the pipeline is fixed to a sample rate of 16kHz, it is likely that many sounds generated using this technique can be used as source material for the game.</p>

<p>To speed up the process, I generated 50 text prompts with ChatGPT which were in turn used to generate audio. The prompts followed our internal sound direction guidelines. This process took about 5 minutes on a GPU, saving a lot of time I would otherwise have to spend getting source material.</p>

<p>2 of the files contained musical elements and were discarded. 3 files contained excessive noise and were also discarded.</p>

<figure style="float: none">
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_water_1.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_water_2.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <audio controls="">
    <source src="	https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/audio/2023_04_25_olivegr_ai_sfx_water_3.mp3" type="audio/mpeg" />
    Alternate Text
  </audio>
  <figcaption>AI Generated Water Effects</figcaption>
</figure>

<p>To hear the final results of this process, follow the development of Sacred Gems on the official development <a href="discord.gg/hGx6qxKMD3">Discord</a> server and wishlist the game on <a href="https://store.steampowered.com/app/1739260/Sacred_Gems/">Steam</a>!</p>

<figure style="float: none">
   <img src="https://www.uio.no/english/studies/programmes/SMC-master/blog/assets/image/2023_04_25_olivegr_sg.gif" width="auto" />
</figure>

<h1 id="will-ai-take-your-sound-design-gig">Will AI Take Your Sound Design Gig?</h1>
<p>As it stands, I will occasionally be using AudioLDM to generate source material for designs. While text-to-audio is not quite ready to replace current workflows, it is only a matter of time. That said, these tools can still save you time. If you know what kind of frequency content you need for a design, but are not picky about what the sound containing those frequencies actually is, then this is a solid method to get what you need quickly.</p>

<p>The implication of being able to generate sounds quickly is that your soundscapes will never become repetitive. New files could be generated upon loading the game, or even a new level. While this thought is currently a novel one, it is the direction we are heading in. As audio directors, composers, and sound designers, we should prepare to work with emerging tools and find ways to control them to provide better services for our clients faster.</p>

<h1 id="video-exploration">Video Exploration</h1>

<iframe width="560" height="315" src="https://www.youtube.com/embed/cgowAgbLTfk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>If you want to see more exploration of the model in real time, check out the video above or follow <a href="https://youtu.be/cgowAgbLTfk">this link</a>!</p>
</div>

  

  <a class="u-url" href="/machine-learning/2023/04/25/olivegr-text-to-audio.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
