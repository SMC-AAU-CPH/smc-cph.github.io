<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>The B Team Dives in Deep (Learning!) | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="The B Team Dives in Deep (Learning!)" />
<meta name="author" content="Jackson Goode, Jarle Steinhovden, Simon Sandvik" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Well, here we are, at the end of a semester where one of the most challenging courses remain - only Rebecca Fiebrink can save us now." />
<meta property="og:description" content="Well, here we are, at the end of a semester where one of the most challenging courses remain - only Rebecca Fiebrink can save us now." />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2019/11/25/b-team-deep.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2019/11/25/b-team-deep.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2019_11_25_stefanof_ml_final.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-11-25T18:30:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2019_11_25_stefanof_ml_final.jpg" />
<meta property="twitter:title" content="The B Team Dives in Deep (Learning!)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Jackson Goode, Jarle Steinhovden, Simon Sandvik"},"dateModified":"2019-11-25T18:30:00+00:00","datePublished":"2019-11-25T18:30:00+00:00","description":"Well, here we are, at the end of a semester where one of the most challenging courses remain - only Rebecca Fiebrink can save us now.","headline":"The B Team Dives in Deep (Learning!)","image":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2019_11_25_stefanof_ml_final.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2019/11/25/b-team-deep.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Jackson Goode, Jarle Steinhovden, Simon Sandvik"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2019/11/25/b-team-deep.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      The B Team Dives in Deep (Learning!)
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2019-11-25T18:30:00+00:00"
        itemprop="datePublished"
      >Nov 25, 2019 •
      </time>
         
      <a href="/authors/jacksongoode.html">Jackson Goode,</a>
           
      <a href="/authors/jarlesteinhovden.html">Jarle Steinhovden,</a>
           
      <a href="/authors/simonsandvik.html">Simon Sandvik</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><h1 id="gyro-synth-a-musical-instrument-built-with-the-wekinator">Gyro-synth: A Musical Instrument Built with the Wekinator</h1>

<p>For the November 21st performance, our group trained a Machine Learning (ML) model using the <a href="http://www.wekinator.org/">Wekinator</a> application to easily map a synthesizer with a mobile OSC controller. We used the gyroscope sensor in our phones and an FM synthesizer application that was included in the example applications provided by the Wekinator author. The gyroscope sensory sends three continuous data streams for the x, y, and z axes, and the FM synth had three input parameters for modulation, frequency, offset. The gyroscope data streams were sent directly to the IP of our PCs with the port and OSC message specified within the Wekinator program via two different OSC apps: Sensors2OSC for two of the members’ Android smartphones, and GyrOSC for the third member’s iPhone. The Wekinator, simply, is a software that makes the process of building a custom musical controller using ML easy and approachable (Fiebrink, 2010).</p>

<p>Here’s a brief intro from it’s developer, Rebecca Fiebrink
<a href="http://www.youtube.com/watch?v=dPV-gCqy9j4"><img src="http://img.youtube.com/vi/dPV-gCqy9j4/0.jpg" alt="Intro to Wekinator" /></a></p>

<h2 id="setup">Setup</h2>

<p>Once these apps were configured with each of our PC’s Wekinator applications, we specified the project parameters needed for our performance: port number, OSC message, 3 inputs, 3 outputs, output type as continuous, and model type as neural network. Afterwards, we chose unique parameters from the 3 outputs available within the Wekinator that would be mapped to the synth and would serve as our first training state. As a group, we first configured silence to the state of the phone held with the screen facing the user. The direct forward tilt was also roughly mapped to a different note on each device that would form a major chord when played together by all three devices. We then took these 5 recordings of 3-dimensional gyroscope data and <em>trained</em> (that’s “ML-talk”) the model using the Wekinator. Once complete, we were able to click “Run” and use our phone’s gyroscope as a controller to send both novel inputs to the Wekinator and produce novel outputs via the trained model’s interpolations.</p>

<p>The Wekinator then deploys a supervised learning algorithm on the labeled data we generate when recording OSC input messages while playing the FM synth. The model that we trained from this data was then able to predict a blend of these outputs even when receiving new data. The effect of this model allows us to have a continuous mapping of our synth to (virtually) any orientaton of our phones.</p>

<h2 id="performance">Performance</h2>

<p>In our performance, we were able to achieve a level of expressivity and responsiveness that was able to be quickly achieved through limited training, and with just a few sonic anchors to navigate between. During our testing and evaluation of the configuration, we noticed that the continuity of the FM synthesizer’s parameters in response to the gyroscope was dependent on whether the labeled states of the FM synth were able to correspond between one another in gyroscopic space. The Wekinator’s ability to seamlessly organize various sounds within these states effectively allowed a fluid process: from a) idea, to b) mapping the parameters of the synth to our gyroscopic movements, to c) performance.</p>

<h1 id="classifying-impact-sounds-using-scikit-learn">Classifying Impact Sounds using Scikit-learn</h1>

<p>In addition to the creation of new instruments using the Wekinator, we dug a little deeper within some light coding using the Scikit-learn toolkit. Our dataset consisted of 4 categories of short impact sounds: glass, rock, metal, and wood. We chose these categories for their unique sonic characteristics. Assessing our dataset, we checked that a random sample of these sounds could be accurately categorized by each of us, and thus, share some consistency across each category. Theoretically: employing an ML technique upon this dataset ought to learn a set of features similar to how humans may recognize these four categories apart and be able to categorize an unfamiliar sample from our dataset into one of these categories with reasonable accuracy.</p>

<h2 id="an-overview">An Overview</h2>

<p>We used the <a href="https://scikit-learn.org/stable/tutorial/basic/tutorial.html">Scikit-learn</a> package to train a supervised neural network classifier using our dataset (Scikit-Learn…). Since we were using supervised learning, our audio samples were loaded and labeled via our own labels. Here we chose a sample rate at which the audio files would be resampled. We chose the scalar and vectorial features that corresponded to sonic elements within the sound samples. These features were then extracted and appended into an array along with an array for the feature’s labels. Finally, the model was trained using a 70/30 split of the dataset (very typical) with 70% of the data used for a training set and 30% as a validation set for the classifier. Evaluation was based on the number of mislabeled examples, a confusion matrix to describe the frequency of label identity within each category, as well as a metric for accuracy across all classification of the validation set. Upon evaluation, parameters like sampling rate, scalar and vectorial feature set, hidden layer count and size, epoch maximum count, and activation function (Figure 1).</p>

<p><img src="/assets/image/2019_11_25_stefanof_act_functions.png" width="500" />
Figure 1: Some of the more common activation functions (Jadon, 2019)</p>

<h2 id="testing-and-configuration">Testing and Configuration</h2>

<p>After running a few evaluations of Team B’s dataset, we decided that because a lot of the sonic energy of these impact sounds was in the high end, it would improve the model to choose a sampling rate of 44.1kHz, which was the actual sample rate for our audio samples. During our feature selection, we found it difficult to discern which features dramatically improved the predictions as we weren’t able to simply A/B test the model. However, we did note that a large amount of features lead to the detriment of the model’s predictive ability. A fewer number of features were able to provide higher accuracy in our tests. This is likely due to too many irrelevant sonic features “polluting” the extraction of salient features within the sample pool. In an attempt to A/B test all of the features, we found that the only scalar feature that did not improve the model was spectral flatness. After testing several different activation functions and hidden layer counts and sizes, our best results ended up merely being a single layer with 100 nodes using the ReLU activation function.</p>

<h2 id="results">Results?</h2>

<p><img src="/assets/image/2019_11_25_stefanof_classifier.png" width="500" />
Figure 2: Jarle’s results for one attempt</p>

<p>Building a model to categorize Team B’s dataset was largely successful, with an accuracy of 94% over a 10-fold validation (at our best, see Figure 3). Afterwards, we trained the model with another group’s dataset to compare whether our configuration would apply to another database: it did not. We found that Team B and Team C compiled <em>very</em> different datasets, resulting in less accurate classifiers built from the sample database. We were only able to achieve a consistent 70%, regardless it seemed, of changes to the activation function or hidden layer architecture. Team C’s sounds, it seemed from examination by ear, shared less sonic similarities, and appeared to be sourced from multiple different sample packs (shame on them!).</p>

<p><img src="/assets/image/2019_11_25_stefanof_classifier2.png" width="500" />
Figure 3: Jackson’s results averaged over 10 iterations</p>

<p>In any case, through this module, we were able to learn quite a bit about the theory (and some practice) of basic machine learning. We trained an instrument using a readily made neural model to produce control dynamic synth in space and a classifier that was able to recognize categories of sound using their spectral qualities accurately. With this perspective, we did succeed in dipping our toes into the great big world of machine learning.</p>

<h1 id="references">References</h1>

<p>Fiebrink, Rebecca, and Perry Cook. “The Wekinator: A System for Real-Time, Interactive Machine Learning in Music.” <em>Proceedings of The Eleventh International Society for Music Information Retrieval Conference (ISMIR 2010)</em>, Jan. 2010.</p>

<p>Jadon, Shruti. “Introduction to Different Activation Functions for Deep Learning.” <em>Medium</em>, 6 Nov. 2019, https://medium.com/@shrutijadon10104776/survey-on-activation-functions-for-deep-learning-9689331ba092.</p>

<p><em>Scikit-Learn: Machine Learning in Python — Scikit-Learn 0.21.3 Documentation</em>. https://scikit-learn.org/stable/index.html. Accessed 23 Nov. 2019.</p>

<p><em>Quick Walkthrough of Wekinator. YouTube</em>, https://www.youtube.com/watch?v=dPV-gCqy9j4. Accessed 25 Nov. 2019.</p>
</div>

  

  <a class="u-url" href="/machine-learning/2019/11/25/b-team-deep.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
