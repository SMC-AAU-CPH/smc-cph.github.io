<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Can Machine learning classify audio effects, a dry to wet sound ? | The SMC Blog</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="Can Machine learning classify audio effects, a dry to wet sound ?" />
<meta name="author" content="Abhishek Choubey" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Distortion or No Distortion - Machine learning magic" />
<meta property="og:description" content="Distortion or No Distortion - Machine learning magic" />
<link rel="canonical" href="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2021/09/20/abhishec-audio-effect-classification-ml.html" />
<meta property="og:url" content="https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2021/09/20/abhishec-audio-effect-classification-ml.html" />
<meta property="og:site_name" content="The SMC Blog" />
<meta property="og:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2021_09_20_abhishec_excerpt_ml.PNG" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-20T19:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2021_09_20_abhishec_excerpt_ml.PNG" />
<meta property="twitter:title" content="Can Machine learning classify audio effects, a dry to wet sound ?" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Abhishek Choubey"},"dateModified":"2021-09-20T19:00:00+00:00","datePublished":"2021-09-20T19:00:00+00:00","description":"Distortion or No Distortion - Machine learning magic","headline":"Can Machine learning classify audio effects, a dry to wet sound ?","image":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2021_09_20_abhishec_excerpt_ml.PNG","mainEntityOfPage":{"@type":"WebPage","@id":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2021/09/20/abhishec-audio-effect-classification-ml.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://smc-aau-cph.github.io/smc-cph.github.io/assets/image/2022_07_20_stefanof_SMC_logo_grey.png"},"name":"Abhishek Choubey"},"url":"https://smc-aau-cph.github.io/smc-cph.github.io/machine-learning/2021/09/20/abhishec-audio-effect-classification-ml.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://smc-aau-cph.github.io/smc-cph.github.io/feed.xml" title="The SMC Blog" /></head>
<body><header class="site-header" role="banner"><div class="hamburger-menu-container">
  <nav>
    <ul>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Topics</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
          
          <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
          
          <li><a href="/motion-capture/">Embodied Interaction</a></li>
          
          <li><a href="/networked-music/">Networked Music</a></li>
          
          <li><a href="/sonification/">Sonification</a></li>
          
          <li><a href="/sound-programming/">Sound Processing</a></li>
          
          <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
          
          <li><a href="/other/">Other</a></li>
          
          <li><a href="/alltopics/">All Topics</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        

        <a href="#" class="drop-btn-hamburger" onclick="handleMenuClick(this)"
          >Projects</a
        >
        <ul class="dropdown-hamburger">
          
          <li><a href="/mini-projects/">Course Mini Projects</a></li>
          
          <li><a href="/applied-projects/">Semester Projects</a></li>
          
          <li><a href="/masters-thesis/">Master's Theses</a></li>
          
          <li><a href="/projects/">All Projects</a></li>
          
        </ul>

        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/people/">People</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/about/">About</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/Guides/">Guides</a>
        
      </li>
      
      <li class="page-link-hamburger">
        
        <a href="/search/">Search</a>
        
      </li>
      
    </ul>
  </nav>
</div>
<div class="wrapper">
        <div class="title-and-logo-wrapper">
            <a href="/">
                <img class="site-logo" src="/assets/image/2022_07_20_stefanof_SMC_logo_grey.png" />
            </a>
            <p class="site-title">
            The SMC Blog
            </p>
        </div>

        <nav class="site-nav">
        <ul>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Topics</a>
                <ul class="dropdown">
                
                <li><a href="/interactive-music/">New Interfaces for Musical Expression (NIME)</a></li>
                
                <li><a href="/machine-learning/">Machine Learning for Media Experiences</a></li>
                
                <li><a href="/motion-capture/">Embodied Interaction</a></li>
                
                <li><a href="/networked-music/">Networked Music</a></li>
                
                <li><a href="/sonification/">Sonification</a></li>
                
                <li><a href="/sound-programming/">Sound Processing</a></li>
                
                <li><a href="/spatial-audio/">Spatial User Interfaces</a></li>
                
                <li><a href="/other/">Other</a></li>
                
                <li><a href="/alltopics/">All Topics</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            

                <a href='#' class="drop-btn" onclick="handleMenuClick(this)">Projects</a>
                <ul class="dropdown">
                
                <li><a href="/mini-projects/">Course Mini Projects</a></li>
                
                <li><a href="/applied-projects/">Semester Projects</a></li>
                
                <li><a href="/masters-thesis/">Master's Theses</a></li>
                
                <li><a href="/projects/">All Projects</a></li>
                
                </ul>

            
            </li>
            
            <li class="page-link">
            
                <a href="/people/">People</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/about/">About</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/Guides/">Guides</a>
            
            </li>
            
            <li class="page-link">
            
                <a href="/search/">Search</a>
            
            </li>
            
        </ul>
        </nav>
        <nav class="hamburger-icon-nav"><div class="hamburger-icon-container" onclick="handleHamburgerClick(this)">
  <div class="hamburger-icon-div hamburger-bar1"></div>
  <div class="hamburger-icon-div hamburger-bar2"></div>
  <div class="hamburger-icon-div hamburger-bar3"></div>
</div>
</nav>
    </div>

  <script src="/utils/jquery.js"></script>
  <script src="/utils/hamburger-nav.js"></script>
  <script src="/utils/nav-dropdown-click-handler.js"></script>
</header>
<main class="page-content" aria-label="Content">

      <div class="wrapper">
        <article
  class="post h-entry"
  itemscope
  itemtype="http://schema.org/BlogPosting"
>
  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline" align="left">
      Can Machine learning classify audio effects, a dry to wet sound ?
    </h1>
    <p class="post-meta">
      <time
        class="dt-published"
        datetime="2021-09-20T19:00:00+00:00"
        itemprop="datePublished"
      >Sep 20, 2021 •
      </time>
         
      <a href="/authors/abhishekchoubey.html">Abhishek Choubey</a>
        </p>
  </header>

  <div class="post-content" itemprop="articleBody"><p>After the intense weeks of machine learning, what did I learn? Machine learning is hard and it’s a journey. But it is not as mysterious as it used to be anymore! Will Artificial Intelligence and Machine learning take over the world? Not anytime soon and not forever, well that’s debatable. But the world of machine learning is a fascinating one, is it capable of solving all the problems of the world? Definitely not, but for the right challenges applied in the right way, it leads to the astonishing result, and that’s why it is so famous. After days of fiddling around on the internet trying to find inspiration for a project that I wanted to do, I decided to look into if machine learning can distinguish audio effect(s) applied on the audio, essentially classification of a dry audio signal to a wet audio signal.</p>

<h2 id="how-did-i-start">How did I start?</h2>
<p>First I decided on what machine learning technique will I use, supervised or unsupervised? And which techniques among these two categories? After a bit of research, I decided to go with supervised machine learning techniques and apply a couple of them to see which one performs the best. I ended up using Support Vector Machine (SVM), Multilayer Perceptron (MLP), and K-Nearest Neighbour (KNN) for the problem. The next task was to find an appropriate database for training and testing the model I wanted to create. I ended up using the IDMT-SMT-Audio-Effects database, as it had a variety of audio effects and multiple settings on each of them, applied to different types of guitars. It was perfect for me because then I could train my model to not just classify between a dry and wet sound but also classify basically into different positions of dry/wet knob, or different amount/type of same audio effect.</p>

<h2 id="approach">Approach</h2>
<p>I took two approaches while dealing with this problem, the first was to just randomly split the data into training and training parts and use them to train and test the models. The other was to optimize all the processes before we actually train the model, so optimal split of data, Dimensionality Reduction, scaling and so on. The motivation behind this approach was to check how badly the system will perform without the optimization and how much the performance will enhance after applying these optimizing techniques.</p>

<h2 id="dataset">Dataset</h2>
<p>The data set as mentioned above I used was the IDMT-SMT-Audio-Effects, it is a dataset consisting of 55044 audio files recorded a 44.1 kHz, 16 bit, and in mono. This is divided into monophonic guitar and bass notes, and polyphonic guitar sounds, with an overall of 11 different types of audio effects applied to these recordings, you can get the dataset with detailed information here []. I ended up using a small chunk of the data. I used the monophonic guitar notes with distortion applied to them and the corresponding no-effect audio files. There are three different distortion settings in the audio effects, so it gave me enough bracket of audio files to play with.</p>

<h2 id="system-architecture">System Architecture</h2>
<p>As discussed above, the system here uses supervised machine learning techniques to classify between audio samples with three variations of distortion audio effect and audio samples without any audio effect, essentially trying to classify between dry and wet audio samples. First, I extracted the features using the python library Librosa, plotted them for visual representation using matplotlib as shown in figure 1 and figure 2, and understanding their distribution.</p>

<figure style="float: auto">
   <img src="/assets/image/2021_09_20_abhishec_scatter2D_ml.png" alt="" title="Features Scatter Plot in 2D" width="auto" /> <figcaption>Figure 1: Features Scatter Plot in 2D</figcaption>
</figure>

<figure style="float: auto">
   <img src="/assets/image/2021_09_20_abhishec_scatter3D_ml.png" alt="" title="Features Scatter Plot in 2D" width="auto" /> <figcaption>Figure 1: Features Scatter Plot in 3D</figcaption>
</figure>

<p>After that I divided the dataset into a 70/30 split using Scikit learns [train_test_split] method <a href="https://scikit-learn.org/stable/index.html">Scikit learn</a> is also the library that I have extensively used in this project for employing all the machine learning techniques. Subsequently, I used SVM, MLP, and KNN and got the results. A brief introduction to these machine learning models is given below:</p>

<p><a href="https://scikit-learn.org/stable/modules/classes.html?highlight=svm#module-sklearn.svm">Support Vector Machine (SVM)</a> – SVM has shown excellent results in binary and multi-class classification tasks, this technique tries to divide the dataset using a hyperplane separating negative and positive points with maximum distance.</p>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html?highlight=mlp#sklearn.neural_network.MLPClassifier">Multilayer perceptron (MLP)</a> neural network classifier – a multi-layered neural network technique MLP has been used in various tasks ranging from image to audio classification. When there are high complexities in the features of the dataset, MLP is found to be successful in classification problems.</p>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html?highlight=knn#sklearn.impute.KNNImputer">K-Nearest Neighbor (KNN)</a> – Being applied in various musical and audio analysis applications, the basic idea behind KNN is to allow a small number of neighbors to influence the decision of the organization of the dataset. It assumes that similar things exist in close proximity.</p>

<p>After modeling the system using these techniques, parameter tuning, scaling, and Dimensionality reduction techniques are employed to increase the efficiency. To increase the performance of the system firstly a different cross-validation approach using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html">Repeated Stratified KFold (RKF)</a> to split the data for training and testing is applied. In Repeated Stratified KFold, the dataset is divided into ‘K’ number of folds and the cross-validation procedure is repeated multiple times, and the mean of all the runs across all the folds are taken. After Splitting the data using RKF, it is scaled using the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html">standard scaler</a> from the scikit learn library, we need scaling so that the machine learning model interprets the data on the same scale.
After the scaling Dimensionality Reduction (DR) technique is used for reducing the feature dimension, also to find the best optimum features we can use to classify the data. In the proposed system, <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">Principal Component Analysis (PCA)</a> technique is used. PCA is a highly used DR technique that essentially transforms a large set of variables into a smaller one by trying to maximize the sum of the squared distance from the origin to the projected points.
After tuning the dataset and features the three machine learning techniques stated above are implanted again to examine the increase in performance.</p>

<h2 id="results">Results</h2>
<p>After tuning the dataset and features I noticed a significant amount of improvement in all three techniques, with Multilayer perceptron performing the best among all giving an accuracy of 97.6% jumping from 83% before optimization, Support Vector machine produced an accuracy of 96.6% while it was % before, and K-Nearest Neighbor being the last still saw a significant improvement from 66% to 95%.</p>

<h2 id="conclusions">Conclusions</h2>
<p>In this project I tried classification of audio samples with audio effect – Distortion applied at three different settings to the audio signals without any effect. Three different supervised machine learning techniques have been applied in order to determine the best-performing technique. Considering that the task was the classification of similar types of audio effects particularly distortion to a dry signal the acquired accuracy of the system, ranging from ~82% to jumping to 96% with optimization can be taken as a decent sub-par result to the problem. Although the accuracy can be improved it was noticed that most of the wrongly classified samples came from the no-effect category and were misplaced due to the affinity of the sound to the ones for which the effect was applied. Finally, in order to make the system more robust, Hyperparameter tuning, noise addition, and other such techniques can be taken into consideration for future prospects.</p>
</div>

  

  <a class="u-url" href="/machine-learning/2021/09/20/abhishec-audio-effect-classification-ml.html" hidden></a>
</article>

<script src="/utils/slideshow.js"></script>
<script src="https://unpkg.com/wavesurfer.js@5.0.1/dist/wavesurfer.js"></script>
<script src="/utils/waveform.js"></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The SMC Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">The SMC Blog</li><li><a class="u-email" href="mailto:cer@create.aau.dk">cer@create.aau.dk</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://www.twitter.com/smc-aau-cph"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">smc-aau-cph</span></a></li><li><a href="https://youtube.com/c/smc-aau-cphr/videos"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#youtube"></use></svg> <span class="username">SMC_master</span></a></li><li><a href="/feed.xml"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#rss"></use></svg> <span>RSS feed</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>The student-led blog of the Aalborg University Copenhagen (AAU-CPH) master&#39;s programme in Sound and Music Computing (SMC).</p>
      </div>
    </div>

  </div>

</footer>


    <!-- include comments here -->

  </body>

</html>
